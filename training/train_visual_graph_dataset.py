import os
import sys
import pathlib

import click

from kgcnn.data.base import MemoryGraphDataset
from kgcnn.data.visual_graph_dataset import VisualGraphDataset
from kgcnn.hyper.hyper import HyperParameter
from kgcnn.utils.cli import echo_info, echo_success, echo_error
from kgcnn.data.serial import deserialize as deserialize_dataset


PATH = pathlib.Path(__file__).parent.absolute()
HYPER_PATH = os.path.join(PATH, 'hyper', 'hyper_visual_graph_datasets.py')


@click.command()
@click.option('--model', type=click.STRING, default='GCN',
              help='The base model to be trained to predict the target values.')
@click.option('--xai-method', type=click.STRING, default=None,
              help='The XAI method to be used to create the explanations for the given model. If a '
                   'self-explaining model is used, this option can be ignored')
@click.option('--dataset', type=click.STRING, default='mock',
              help='Name of the dataset to be used for training.')
@click.option('--hyper', type=click.STRING, default=HYPER_PATH,
              help='Filepath to the hyperparameter config file to be used.')
@click.option('--make', type=click.STRING, default='make_model',
              help='Name of the "make" function or model to use')
@click.option('--gpu', type=click.INT, default=0,
              help='GPU index used for training')
@click.option('--fold', type=click.INT, default=0,
              help='Split or fold indices to run')
def main(model: str,
         xai_method: str,
         dataset: str,
         hyper: str,
         make: str,
         gpu: int,
         fold: int):
    """
    Train a model of choice on a "Visual Graph Dataset" (VGD).

    Such a VGD is a special dataset
    for *Explainable AI* (XAI). Besides the main prediction target, such VGDs are also evaluated for
    different explainability metrics, such as:

    * Explanation Accuracy: If the dataset contains ground truth explanations they are compared with
      the explanations generated by the model.

    * Sparsity: Good explanations should be sparse. This value between 0 and 1 illustrates the percentage
      of the input elements which have been marked as "important" (binary after thresholding).

    This means that the chosen model should be capable to produce input-attributional explanations. This
    kind of explanation assigns one or multiple "importance" value between 0 and 1 to each element of the
    input graph (nodes & edges) which determine how important that respective element was for the outcome of
    the target value prediction.
    """

    echo_info(f'attempting training of model "{model}" and XAI method "{xai_method}" on dataset {dataset}')
    # Technically the values provided through the command line options do not provide enough information to
    # accurately to fully specify a model training process. This is why the finer details should be encoded
    # within a dictionary structure inside an additional hyperparameter module, whose path we also need to
    # provide.

    # Given the path, this object will read that file and provide the correct configuration dict with all
    # the details about the training specification, given the model name and the dataset name (because
    # the hyperparameter module may contain specifications for different scenarios)
    echo_info(f'loading hyper parameters @ "{hyper}"')
    hyper_params = HyperParameter(
        hyper_info=hyper,
        model_name=model,
        model_module=make,
        dataset_name=dataset
    )

    # hyper_params["data"]["dataset"] is a dictionary containing the detailed specification of the dataset
    # to be used for this experiment. "deserialize_dataset" will use the information from this dict to
    # create and return the corresponding dataset object.
    echo_info(f'loading dataset with name "{dataset}"')
    visual_graph_dataset: VisualGraphDataset = deserialize_dataset(hyper_params['data']['dataset'])

    if not isinstance(visual_graph_dataset, VisualGraphDataset):
        echo_error(f'the given dataset {dataset} is not a visual graph dataset and cannot be used with '
                   f'this command.')
        return 1

    # This method will make sure that the dataset exists in the filesystem, if it does not already it is
    # being downloaded
    visual_graph_dataset.ensure()

    # This method will read the actual dataset into memory
    visual_graph_dataset.read_in_memory()

    return 0


if __name__ == '__main__':
    sys.exit(main())
